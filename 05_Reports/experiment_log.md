# 実験記録: SLMセマンティック・ラウンドトリップ・ベンチマーク

**本文書について:** この文書は、「SLMセマンティック・ラウンドトリップ・ベンチマーク」研究の初期計画から最終分析、そして結論の変遷に至るまでの思考プロセスと実験結果を時系列で記録したものです。内容は`SLM_ARMOR_2_Interim_Report.md`および`analysis_report_20251228.md`から統合・再構成されました。

---

## セクション1: 初期実験と設計思想

### 1.1. 目的と背景
本研究は、小規模言語モデル（SLM/LLM）が仕様とコード間の相互変換をどの程度決定論的に実行できるかを評価する総合的なベンチマークの構築を目指す。初期計画では、複数のモデル、仕様言語、プロンプトスタイルを組み合わせ、意味論的な往復変換（Semantic Round-trip）テストを通じて、モデルの決定論的な信頼性を測定することを目的とした。

### 1.2. 初期結果：成功パターンの発見
最初の網羅的テストでは、以下の重要な成功パターンが確認された。

- **英語環境での成功:**
  - `llama3.2:3b` は、`pseudocode` と `fewshot` プロンプト、および `s_expression` / `minilang` と `hyper_guided` プロンプトの組み合わせで、卓越した安定性を示した。
- **プロンプトスタイルの重要性:**
  - `zeroshot` プロンプトは全ての組み合わせで失敗し、`fewshot` や `hyper_guided` といった文脈情報がいかに重要であるかが証明された。

---

## セクション2: 知見の深化に向けた追加実験

### 2.1. 日本語テスト：モデルの言語適性の発見
- **`llama3.2:3b`の苦戦:** 英語では優秀だった `llama3.2:3b` は、日本語の `pseudocode` プロンプトでは「戻り値」を「戸り値」と誤変換するなど、一貫した出力を生成できず失敗した。
- **`gemma3:4b`の成功:** 一方、`gemma3:4b` は、日本語の `pseudocode` と `hyper_guided` プロンプトの組み合わせで安定した性能を示し、**日本語環境における高い信頼性**を持つモデルであることが新たに発見された。

### 2.2. ロジバン語テスト：「メタ言語」の重要性の発見
- **仮説:** 「LLMは記号から記号への変換が得意」という仮説に基づき、モデルが意味を理解できないロジバン語でも、S式のような記号的な仕様を与えればパターンマッチングで成功するのではないか、と考えた。
- **結果:** **仮説は棄却された。** `gemma3:4b` は、ロジバン語で書かれたプロンプトの指示を全く理解できず、英語で応答してしまった。
- **結論:** この失敗は、**モデルがプロンプトの指示言語（メタ言語）自体を習熟していることが、あらゆる高度なプロンプト技術の前提条件である**という極めて重要な知見をもたらした。

### 2.3. 「記号から記号へ」仮説の再検証とテスト基盤の改善
- ロジバン語テストの失敗を受け、仮説を再検証するため、モデルが得意な**英語**を指示言語とし、仕様言語に記号的な**S式**を用いたテストを実施した。その結果、`llama3.2:3b` は`hyper_guided`プロンプトで完璧な性能を示し、「LLMは記号から記号へのパターン変換が得意」という仮説は、**モデルが理解できるメタ言語で指示を与えれば**有効であることが証明された。
- これら一連の失敗分析を通じて、テスト基盤の出力クリーニングや比較ロジックの堅牢化、多言語対応などの改善が継続的に行われた。

---

## セクション3: 主実験の分析

`analysis_report_20251228.md`より転記。これは、24種類のモデルに対する主実験（各36試行）の結果分析である。

### 3.1. パフォーマンス上位モデル
- **`gemma3:4b`**: 最も堅牢で汎用性が高いモデルとして際立っている。
- **`falcon3:3b`**: `gemma3:4b`に匹敵する強力なパフォーマンスを示した。
- **`llama3.2:3b`**: こちらも優れた結果を残しており、特に`hyper_guided`プロンプトとの相性が良い。

### 3.2. 中堅およびその他のモデル
- **`yi:6b`**: `en, minilang, hyper`という特定の条件下でのみ一貫して成功。プロンプト形式や言語に敏感である可能性が示唆された。
- **その他のモデル**: `phi3:mini`などは限定的な成功に留まり、`tinyllama`などは10サイクルを完走できなかった。

### 3.3. 詳細な失敗事例分析: `qwen3:0.6b`
`en_minilang_hyper_guided`テストにおいて、9サイクルまで完璧に成功し、最後の10サイクル目で失敗した。原因は意味論的な誤解ではなく、関数定義のコロン (`:`) を欠落させるという**些細な構文エラー**であった。これは、意味を理解していても、確率的な揺らぎによって予期せぬエラーを生む可能性を示唆しており、厳格な検証ループの重要性を浮き彫りにした。

---

## セクション4: 「揺らぎ吸収テスト」による比較分析

### 4.1. 分析の目的と計画
モデルの「本質的な論理能力」と「出力形式の安定性」を切り分けるため、「揺らぎ吸収テスト（Forgiving Test）」を計画。具体的には、LLMの応答から最後に見つかったMarkdownコードブロックを抽出するロジックを実装し、厳格テスト（最初のコードブロックを抽出）と比較分析を行った。

### 4.2. 比較結果と当時の考察
- **全体的な傾向:** 揺らぎ吸収テストの結果、**全体として成功数が大幅に増加**した。これは、厳格テストにおける失敗の多くが、出力形式の揺らぎに起因していたことを強く裏付けるものと当時は考えられた。

- **モデルのカテゴリ分類（当時の仮説）:**
  - **カテゴリA (高能力・高安定性):** `gemma3:4b`, `falcon3:3b`, `llama3.2:3b`。厳格テストでも寛容テストでも高性能。
  - **カテゴリB (高能力・低安定性):** `yi:6b`, `llama2:7b`。寛容テストで性能が飛躍的に向上。後処理で性能を発揮するポテンシャルを持つと考えられた。
  - **カテゴリC (低能力):** `tinyllama`など。どちらのテストでも失敗が多く、本質的な能力不足が示唆された。

### 4.3. 当初の結論
この比較分析を通じ、「後処理の有効性」と「モデル特性の解明」という知見が得られた。特にカテゴリBの存在は、堅牢なパーサーを組み合わせることの重要性を示す強力な証拠と見なされた。

---

## セクション5: 最終結論への変遷 - 大規模実験による仮説の棄却

`academic_paper_draft.md`に最終的にまとめられた知見。

- **背景:** 上記セクション4の結論（特にカテゴリBの発見）の統計的信頼性を担保するため、6つの主要モデルに対し、試行回数を30回/組み合わせ（合計360試行）に増やした大規模な追加実験が実施された。
- **結果:**
  - 最も劇的な変化を見せた`llama2:7b`の性能向上率（+19.4ポイント）は、大規模実験では**+0.6ポイント**に留まり、再現されなかった。
  - 他のモデルの性能変化も、-3.1から+1.7ポイントという非常に狭い範囲に収まった。
- **最終結論:**
  1.  **後処理の効果は限定的:** 主実験で観測された「揺らぎ吸収による劇的な性能向上」は、小標本に起因する偶然の結果であった可能性が極めて高い。
  2.  **根源的な課題は「反復安定性」:** モデルの信頼性を左右する支配的な要因は、出力形式の揺らぎのような表層的な問題ではなく、複数サイクルにわたって意味的一貫性を維持する**「反復安定性」そのものの欠如**である。
- **意義:** この結論の変遷は、小標本での発見に過度に依存することの危険性と、再現性を確認するための大規模な追加実験の重要性を示す実例となった。最終的に、プロジェクトの結論は`README.md`にも反映され、整合性が確保された。

---

## セクション6: 複雑タスク（FizzBuzz）による一般化検証実験

### 6.1. 目的と背景
これまでの実験は、極めて単純な`get_magic_number`関数に限定されていた。本研究の結論、特に「反復安定性」の重要性という知見の一般化可能性を検証するため、より複雑なロジック（条件分岐、剰余演算）を含む古典的なプログラミング問題`FizzBuzz`を新たなテストケースとして追加実験を行った。対象モデルは、大規模実験で良好な成績を収めた`gemma3:4b`、`falcon3:3b`、`llama3.2-3b`の3つ。

### 6.2. 実験結果と考察

**表: get_magic_number (n=360) と fizzbuzz (n=360) の成功率比較**

| モデル (Model) | テストケース (Test Case) | 厳格テスト成功率 (Strict) | 寛容テスト成功率 (Forgiving) |
| :--- | :--- | :--- | :--- |
| `gemma3:4b` | `get_magic_number` | 56.7% (51.5-61.7) | 54.7% (49.6-59.8) |
| | `fizzbuzz` | **83.9%** (79.7-87.3) | **87.5%** (83.7-90.5) |
| `falcon3:3b` | `get_magic_number` | 54.2% (49.0-59.2) | 51.1% (46.0-56.2) |
| | `fizzbuzz` | **61.1%** (56.0-66.0) | **62.2%** (57.1-67.1) |
| `llama3.2-3b` | `get_magic_number` | 31.1% (26.5-36.1) | 32.8% (28.1-37.8) |
| | `fizzbuzz` | **12.2%** (9.2-16.0) | **11.9%** (9.0-15.7) |

#### 6.2.1. 仮説1「複雑なタスクでの性能低下」の検証 → 棄却と新たな洞察

当初、「タスクの複雑化は反復安定性を低下させる」と予測していたが、結果はこの仮説を単純には支持しなかった。驚くべきことに、`gemma3:4b`と`falcon3:3b`は、より複雑な`fizzbuzz`タスクで**成功率が大幅に向上**した。これは、タスクの複雑性という一次元的な指標だけでは性能を予測できず、**タスクの性質とモデルの学習内容との親和性**が極めて重要な変数であることを示唆している。`fizzbuzz`のような典型的な問題は訓練データに豊富に含まれている可能性が高く、これらのモデルがそのパターンを堅牢に学習していたと考えられる。一方で、`llama3.2-3b`は予測通り性能が大きく低下しており、モデルによってタスクへの汎化能力に大きな差があることが浮き彫りになった。

#### 6.2.2. 仮説2「性能階層の維持」の検証 → 支持

`fizzbuzz`テストにおいても、`gemma3:4b` > `falcon3:3b` > `llama3.2-3b` という**性能階層は明確に維持された**。これは、モデル固有の「反復安定性」が、タスクの種類を超えて一貫して現れる基本的な能力であることを強く裏付ける結果である。

#### 6.2.3. 仮説3「後処理効果の限定性」の検証 → 支持

`fizzbuzz`の結果でも、厳格テストと寛容テストの成功率の差は最大でも3.6ポイントに留まり、統計的に見て大きな差は認められなかった。これは、`get_magic_number`実験の結論を追認するものであり、**SLMの信頼性における根本的な課題が、出力形式の揺らぎといった後処理で吸収可能な問題ではなく、モデル自体の意味的一貫性を維持する能力にある**ことを改めて強調している。

### 6.3. FizzBuzz実験の結論

`FizzBuzz`実験は、本研究の核心的知見である「反復安定性」の重要性と、それがモデル固有の特性であることを、より複雑なタスクにおいても確認する上で極めて有益であった。単純な複雑性の増減だけでは性能を予測できないという新たな発見は、今後のベンチマーク設計において、タスクの「典型性」や訓練データにおける出現頻度といった要素も考慮に入れる必要性を示唆している。

---

## セクション7: 対話による結果分析と次期実験計画の策定

`FizzBuzz`実験完了後、対話形式で結果の分析と次の行動計画の策定を行った。このセクションでは、その対話と思考のプロセスを記録する。

### 7.1. 日本語と英語の成功率比較

**問い:** 日本語と英語で成功率に差は出たか？

**分析:** `fizzbuzz`実験の結果を言語ごとに集計したところ、`falcon3:3b`と`llama3.2-3b`は英語のプロンプトで顕著に高い性能を示した一方、`gemma3:4b`は日本語でも同等以上の性能を維持した。これは、モデルの訓練データやアーキテクチャに起因する言語適性の差が、タスクの成功率に大きく影響することを示している。

### 7.2. 最も成功率の高いプロンプト方式の特定

**問い:** プロンプトの方式で最も成績が良いパターンは何か？

**分析:** 仕様言語とプロンプトスタイルの組み合わせを分析した結果、**`pseudocode` + `hyper_guided`** および **`minilang` + `hyper_guided`** の組み合わせが、全体として最も高い成功率を示した。これは、明確な構造と段階的な指示が、モデルの複雑なタスクにおける反復安定性を助けることを示唆している。

### 7.3. 複合的な揺らぎ吸収処理の検討

**問い:** 厳格処理で失敗した後に寛容処理で再試行するような、複合的な仕組みで成功率は向上するか？

**分析:** `fizzbuzz`実験の`strict`モードと`forgiving`モードの結果を比較したところ、両者の成功率の差は数パーセントポイントに留まった。このことから、複合戦略を導入しても、その効果は限定的であると結論付けた。失敗の主要因は、後処理で吸収可能な構文の揺らぎではなく、より根源的な「反復安定性」の欠如にあることが改めて示唆された。

### 7.4. 次期実験戦略の策定

**問い:** 全ての実験結果を総合し、全LLMに対して最も成功率が高くなる方法を提案せよ。

**提案:** 最終的に、汎用的な単一構成と、より高度な適応的戦略の2つが提案された。次期実験では、後者の**「モデルの特性を考慮した適応的戦略」**を検証するための環境を整備することとなった。この戦略は以下のステップで構成される。

1.  **言語適性の事前評価:** モデルごとに得意な言語（英語 or 日本語）を判定する。
2.  **最適プロンプトの選択:** 判定された言語で、`pseudocode` + `hyper_guided` を第一候補として実行する。
3.  **複合的後処理の適用:** `strict`モードで評価後、失敗した場合のみ`forgiving`モードで再評価する。
